import pdfplumber
from transformers import BertTokenizer, BertModel
import torch
import numpy as np
from sklearn.decomposition import PCA


tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = BertModel.from_pretrained("bert-base-uncased")
model.eval()

pdf_path = "/Workspace/Users/dbuser19@meteoros.ai/Sample Business Report.pdf"  

text = ""
with pdfplumber.open(pdf_path) as pdf:
    for page in pdf.pages:
        content = page.extract_text()
        if content:
            text += content + " "

words = text.lower().split()
words = [w.strip(".,!?;:()[]\"") for w in words if w.isalpha()]
unique_words = list(set(words))



embeddings_768 = []
valid_words = []

for word in unique_words:
    inputs = tokenizer(word, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
    vec = outputs.last_hidden_state[0][1].numpy()
    embeddings_768.append(vec)
    valid_words.append(word)

X = np.array(embeddings_768)


pca8 = PCA(n_components=8).fit_transform(X)
pca16 = PCA(n_components=16).fit_transform(X)
pca32 = PCA(n_components=32).fit_transform(X)


with open("bert_embeddings_8.txt", "w") as f8:
    for i, word in enumerate(valid_words):
        f8.write(f"{word} {' '.join(map(str, pca8[i]))}\n")

with open("bert_embeddings_16.txt", "w") as f16:
    for i, word in enumerate(valid_words):
        f16.write(f"{word} {' '.join(map(str, pca16[i]))}\n")
        
with open("bert_embeddings_32.txt", "w") as f32:
    for i, word in enumerate(valid_words):
        f32.write(f"{word} {' '.join(map(str, pca32[i]))}\n")


while True:
    word = input("Enter word to search or  type exit to exit").strip().lower()
    if word == "exit":
        break

    found = False
    for dim, file in zip([8, 16, 32], ["bert_embeddings_8.txt", "bert_embeddings_16.txt", "bert_embeddings_32.txt"]):
        with open(file, "r") as f:
            for line in f:
                if line.startswith(word + " "):
                    print(f"{dim}D â†’", line.strip())
                    found = True
                    break

    if not found:
        print("No word found, Generate embedding and writing to file")

        inputs = tokenizer(word, return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)
        vec768 = outputs.last_hidden_state[0][1].numpy()

        # Reduce using previous PCA fits
        vec8 = PCA(n_components=8).fit(X).transform(vec768.reshape(1, -1))[0]
        vec16 = PCA(n_components=16).fit(X).transform(vec768.reshape(1, -1))[0]
        vec32 = PCA(n_components=32).fit(X).transform(vec768.reshape(1, -1))[0]

        with open("bert_embeddings_8.txt", "a") as f8:
            f8.write(f"{word} {' '.join(map(str, vec8))}\n")
        with open("bert_embeddings_16.txt", "a") as f16:
            f16.write(f"{word} {' '.join(map(str, vec16))}\n")
        with open("bert_embeddings_32.txt", "a") as f32:
            f32.write(f"{word} {' '.join(map(str, vec32))}\n")
